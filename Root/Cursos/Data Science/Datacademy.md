# Datacademy

Created: January 17, 2022 4:24 PM
Minded: Yes
Related to La caja de notas (Property): https://www.notion.so/Data-Analyst-y-UX-Designer-0edd391694f34df7b3d696c7b9b78da6
Tag: #datascience

# **¿Qué tipo de información podemos analizar?**

## Tipología de datos

1. Personas → Podemos conocer información de determinados grupos de personas
2. Transacciones → Procedimientos con flujo económico de por medio. Incluye tarjetas de crédito y débito.  Flujos de llamadas.
3. Navegación web → Cookies. Tiempo. Edad. Género.
4. Machine 2 Machine → Conexión de una máquina a otra máquina. GPS. 
5. Biométricos → Huella digital. Genes. Sangre. Saliva.

# **¿Cómo crear empresas y culturas data-driven?**

Entiende qué componentes son necesarios para crear una cultura orientada a los datos.

1. Crear una cultura de datos. Hacer que todos los colaboradores basen sus decisiones en datos.
2. Recolectar toda la información.
3. Medir todo. 
4. Datos relevantes y precisos. ¿Minutos u horas?¿Personas o tiempos?¿La información es precisa y estándar? Transformar las monedas a la misma unidad. Usos horarios.
5. Testear y crear hipótesis. Una hipótesis es una pregunta específica. “Voy a estudiar si las ventas aumentaron por el invierno”
6. Desde los insights de datos a las acciones. Después de saber algo tomaré una acción al respecto.
7. Cumplir las regulaciones de datos. Actuar de manera ética. No tomar decisiones sesgadas.
8. Automatizar. Hacer un estudio una vez y replicarlo para el futuro.

# **Flujo de trabajo en ciencia de datos: fases, roles y oportunidades laborales.**

1. Ingeniero de datos → Obtiene Datos. Genera entornos de información.
    1. Bases de datos
    2. ETLs/APIs
    3. SQL y NoSQL
2. Analista Business Intelligence → Representa y analiza datos. Explica el presente.
    1. Extracción y dashboards
    2. Automatización
    3. SQL y Excel
3. Data Scientist → Representa, analiza datos y predice el futuro
    1. Machine Learning
    2. Modelos estadísticos
    3. R y Python
4. Data Translator → Líder del equipo, Especialista en negocios, intérprete.
    1. Data Scientist - Decision Makers
    2. Destiladores de data
    3. Expertos en necesidad de negocio

# Por qué aprender Python

Porque es la monda.

Es elegante, es rápido, funciona en el backend, ciencia de datos e inteligencia artificial.

# El núcleo de un programa los algoritmos

Un algoritmo es una serie de pasos para resolver un problema.

Un algoritmo informático es una secuencia de instrucciones finitas que llevan a cabo una serie de procesos para dar respuesta a determinados problemas. Es decir, un algoritmo informático resuelve cualquier problema a través de unas instrucciones y reglas concisas, mostrando el resultado obtenido.

# El arte de la programación

Python es un lenguaje de sintaxis sencilla y amigable. Es elegante. Forma buenas prácticas. Python está en todos lados: Drones, cohetes, celulares y laptops. La industria de la tecnología esta creciendo.

# Clase en vivo I

## Jerarquía de la ciencia de datos

![Untitled](Root/Cursos/Data%20Science/Datacademy/Untitled.png)

**ETL** → **Extract, Transform and Load** («extraer, transformar y cargar», frecuentemente abreviado **ETL**) es el proceso que permite a las organizaciones mover datos desde múltiples fuentes, reformatearlos y limpiarlos, y cargarlos en otra base de datos, data mart, o data warehouse para analizar, o en otro sistema operacional para apoyar un proceso de negocio.

![Untitled](Root/Cursos/Data%20Science/Datacademy/Untitled%201.png)

## ¿Qué hace un Data Analyst?

![Untitled](Root/Cursos/Data%20Science/Datacademy/Untitled%202.png)

- Una persona que extrae información valiosa de las bases de datos. Usa SQL y Python.
- Identifica necesidades de la organización.
- Extrae los datos, los limpia y los comunica al resto de áreas.
- Tiene mucha comunicación con las otras áreas.
- Plantea casos de negocio e hipótesis.
- Comunica los hallazgos en tableros y dashboards.

![Untitled](Root/Cursos/Data%20Science/Datacademy/Untitled%203.png)

**Roles relacionados:**

- Business Analyst.
- Data visualization specialist.

### Herramientas y tecnologías:

- SQL para hacer consultas.
- Power BI y Tableau para visualizar.
- Excel y Google Sheets.
- Python.
- Probabilidad.
- Estadística descriptiva.

## ¿Cómo empezar?

- Cómo utilizan las organizaciones con Business Intelligence.
- Consultar bases de datos
- Herramientas de análisis como Excel, Power BI y Tableau.
- Estadística aplicada a análisis de datos.
- Leer sobre la industria que quieres conocer.

# Clase en vivo II

![Untitled](Root/Cursos/Data%20Science/Datacademy/Untitled%204.png)

Un Data Engineer prepara los datos para el resto del equipo.

![Untitled](Root/Cursos/Data%20Science/Datacademy/Untitled%205.png)

Los datos pueden venir tanto de adentro o fuera de la organización.

Los datos deben transformarse para el análisis.

Las bases de datos especializadas para análisis.

OLTP → Bases de datos transaccionales → Bases que siempre están cambiando, son las bases normales de cualquier plataforma.

OLAP → Bases listas para consultas y análisis 

Recordemos que ETL es (Extract, transform, load) → Es el proceso que permite a las organizaciones mover datos desde múltiples fuentes, reformatearlos y limpiarlos.

![Untitled](Root/Cursos/Data%20Science/Datacademy/Untitled%206.png)

OLAP → Data Warehouse → Bases de datos para consultar.

Existen los Data Architects y los Big Data Architects.

## Herramientas y tecnologías

- Python
- Linux
- Automatización y scripting.
- Jupyter Notebooks
- Manejo avanzado de bases de datos SQL y NoSQL.
- Pandas, Dask y Apache Spark.
- Airflow → Automatizar procesos
- Tecnologías cloud → aws, Google Cloud, docker
- Orquestadores Kubernetes.

En ocasiones es necesario usar el computo de diferentes máquinas. Para esto se usan las tecnologías Cloud y los contenedores y los orquestadores.

## Matemáticas

En general este rol no necesita tantas matemáticas.

- Estadística descriptiva

![Untitled](Root/Cursos/Data%20Science/Datacademy/Untitled%207.png)

# Clase en vivo III

Data Science en las empresas y sus equipos

Exploración, transformación y entrenamiento y creación del modelo de machine learning.

![Untitled](Root/Cursos/Data%20Science/Datacademy/Untitled%208.png)

Tomar datos y convertirlos en un producto útil para la organización.

![Untitled](Root/Cursos/Data%20Science/Datacademy/Untitled%209.png)

![Untitled](Root/Cursos/Data%20Science/Datacademy/Untitled%2010.png)

![Untitled](Root/Cursos/Data%20Science/Datacademy/Untitled%2011.png)

Los Data Scientist trabajan más de la mano con el equipo de desarrollo. Los DS deben programar más. Usan Machine Learning y estadística avanzada.

## Herramientas

- Python
- Jupyter Notebooks
- Pandas, Numpy, Matplotlib.
- Algoritmos y librerías de machine learning como scikit-learn y TensorFlow.
- Bases de datos SQL y NoSQL.

## Matemáticas para DS

- Algebra
- Estadística descriptiva e inferencial
- Probabilidad
- Álgebra lineal
- Cálculo

## ¿Cómo empezar?

- Cómo utilizan los datos las organizaciones.
- Programación con Python y sus librerias.
- Usar Jupyter.
- Estadística y probabilidad aplicada.
- Crea un proyecto de análisis.

Un DS

1. Transforma
2. Analiza
3. Identifica
4. Contextualiza

Un DS comprende y da respuestas. Predice el futuro. Reconoce que hay análisis que no son necesarios. Un DS sabe comunicar. Transmitir ideas.

# ****Estadística descriptiva vs. inferencial****

Ejemplo:

1. Descriptiva: Resumir el historial deportivo de un jugador.
2. Inferencial: Predecir desempeño futuro del jugador.

**La estadística descriptiva** se enfoca en resumir un historial de datos.

**La estadística inferencial** predice un comportamiento tras analizar los datos.

La Estadistica presenta ciertas **deficiencias**:

- Depende de la definición del investigador o de quien realiza el analisis.
- No hay una definción objetiva.
- Los diferentes estadisticos descriptivos dan nociones diferentes sobre los mismos datos.

**Estadistico descriptivo:** son las mediciones o métricas de los datos que nos dan información de ellos.

> *"Con frecuencia construimos un caso estadístico con datos imperfectos, como resultado hay numerosas razones por las cuales individuos intelectuales respetables pueden no estar de acuerdo sobre los resultados estadísticos.”*
> 

**Porque aprender estadistica?**

- Resumir grande cantidades de informacion siempre es util.
- Nos ayuda a tomar mejores decisiones.
- Responder preguntas con relevancia social. La estadisitica simpre se usa para caracterizar un pais.
- Reconocer patrones en los datos.
- Descubrir quienes nos estan mintiendo.

# Flujo de trabajo en data science

![Untitled](Root/Cursos/Data%20Science/Datacademy/Untitled%2012.png)

1. **Primer bloque - Ingestas de datos y Validación:** Parte del pre-procesamiento (ETL). Se identifica cuáles son los tipos de datos, cuál es el pipeline o flujo de procesamiento (el cual definirá las transformaciones que se deben hacer sobre los datos para que los datos queden limpios y adaptados al modelo)
2. **Segundo bloque - Preparación y Entrenamiento de modelo:** Fase donde termino de procesar los datos y comienzo a construir el modelo. Se hace un análisis exploratorio, uso de estadística descriptiva, entender si hay correlaciones y hacer posible reducciones de datos.
3. **Tercer bloque - Evaluar modelo, Modelo a Producción y Interacción con usuarios:** Encontramos elementos de estadística como Probabilidad e Inferencia. Se hace uso del Test de Hipótesis.

![Untitled](Root/Cursos/Data%20Science/Datacademy/Untitled%2013.png)

# Tipos de datos

![Untitled](Root/Cursos/Data%20Science/Datacademy/Untitled%2014.png)

1. Categórico nominal: Son categorías no ordenadas. (Ej, color de ojos)
    1. Dicotómicos: Solo dos valores. (Ej, hombre - mujer)
2. Categórico ordinal:  Categorías ordenadas. (Ej, mal - regular - bien)
3. Numéricos discretos: Números enteros.
4. Numéricos continuos: Números decimales.

# Medidas de tendencia central

Las medidas de tendencia central son una forma de resumir nuestra información.

Las medidas de tendencia central nos entregan información respecto a alrededor de qué puntos (números) se encuentran distribuidos nuestros datos. La desventaja principal de las medidas de tendencia central es que pueden ser afectadas por los puntos extremos o valores atípicos.

Las medidas de tendencia central principales son:

- Media (promedio)
- Mediana (El dato central o de la mitad de la muestra)
- Moda (el dato que más se repite, el más común)

![Untitled](Root/Cursos/Data%20Science/Datacademy/Untitled%2015.png)

![Untitled](Root/Cursos/Data%20Science/Datacademy/Untitled%2016.png)

# Medidas de dispersión

### Dispersion en una distribución

- Rango
- Rango Inter cuartil
- Desviación estándar

Dado el grafico

![https://static.platzi.com/media/user_upload/cuadrantes-156ee8f7-f51b-4555-b750-eeb0cd301ad4.jpg](https://static.platzi.com/media/user_upload/cuadrantes-156ee8f7-f51b-4555-b750-eeb0cd301ad4.jpg)

En el **histograma** se ve la distribución de datos visualizando la cantidad de datos referente a cada valor y podemos ver que en este caso es una distribución normal.

### Rango

**El Rango** es la distancia o intervalo entre el valor máximo y el valor mínimo de la distribución, el cual está dado por la resta del valor máximo menos el mínimo siendo este la diferencia.

### Cuartiles

**La Rango Inter cuartil** son los puntos que divide los datos en 4 partes iguales:

Siendo el cuartil 2 es la MedianaEl cuartil 1 es la mitad entre la mediana y el valor mínimoEl cuartil 3 es la mitad entre la mediana y el valor máximo

Y la distancia entre el cuartil 3 y el cuartil 1 se conoce como rango Inter cuartil (IQR).

Los cuartiles separan los datos en 4 partes iguales

Los cuartiles son valores que dividen una muestra de datos en cuatro partes iguales

**1er cuartil (Q1):** 25% de los datos es menor que o igual a este valor.**2do cuartil (Q2):** La mediana. 50% de los datos es menor que o igual a este valor.**3er cuartil (Q3):** 75% de los datos es menor que o igual a este valor.**Rango Inter cuartil:** La distancia entre el primer 1er cuartil y el 3er cuartil (Q3-Q1); de esta manera, abarca el 50% central de los datos.

### Diagrama de caja o box plot

representa gráficamente una serie de datos numéricos a través de sus cuartiles. De esta manera, el diagrama de caja muestra a simple vista la mediana y los cuartiles de los datos. También puede representar los valores atípicos de estos.

En la visualización del rango, el rango Inter cuartil y los cuartiles, se muestra en un **diagrama de caja** que es la gráfica por excelencia para mostrar los datos con respecto a **la mediana** en particular.

# ****Exploración visual de los datos****

***No se trata solamente de tener una imagen de los datos, sino una buena imagen***